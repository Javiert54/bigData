{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías\n",
    "En esta celda importamos las librerías necesarias para el procesamiento de imágenes, manejo de archivos, operaciones numéricas, construcción de modelos de deep learning y visualización de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descompresión del dataset\n",
    "Aquí sería donde descomprimo el dataset, pero como estoy usando jupyter, debo borrar la carpeta (si existe) y volver a descomprimirla. Luego veremos por qué es necesario borrar la carpeta cada vez que ejecutemos el cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta 'Chessman-image-dataset' eliminada.\n",
      "Archivo 'archive.zip' extraído en '.'.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def eliminar_carpetas(carpeta):\n",
    "    if os.path.exists(carpeta):\n",
    "        shutil.rmtree(carpeta)\n",
    "        print(f\"Carpeta '{carpeta}' eliminada.\")\n",
    "    else:\n",
    "        print(f\"La carpeta '{carpeta}' no existe.\")\n",
    "\n",
    "def extraer_zip(archivo_zip, destino):\n",
    "    with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(destino)\n",
    "        print(f\"Archivo '{archivo_zip}' extraído en '{destino}'.\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "carpeta_a_eliminar = 'ruta/a/tu/carpeta'\n",
    "archivo_zip = 'ruta/a/tu/archivo.zip'\n",
    "destino_extraccion = 'ruta/a/tu/destino'\n",
    "\n",
    "eliminar_carpetas(\"Chessman-image-dataset\")\n",
    "extraer_zip(\"archive.zip\", \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapeo de clases y tamaño de imágenes\n",
    "En esta celda definimos un diccionario que mapea los nombres de las piezas de ajedrez a etiquetas numéricas y establecemos el tamaño estándar de las imágenes a 150x150 píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una relación entre los nombres de las imágenes y las clases\n",
    "MAP_CHARACTERS = { 0: 'Bishop', 1: 'King', 2: 'Knight', 3: 'Pawn', 4: 'Queen', 5: 'Rook' }\n",
    "# Vamos a standarizar todas las imágenes a tamaño 64x64\n",
    "IMG_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para cargar los datos\n",
    "Declaramos dos funciones para cargar los datos. Una dedicada a la fracción train y la otra para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_set(dirname, map_characters, verbose=True):\n",
    "\t\"\"\"Esta función carga los datos de training en imágenes.\n",
    "\n",
    "\tComo las imágenes tienen tamaños distintas, utilizamos la librería opencv\n",
    "\tpara hacer un resize y adaptarlas todas a tamaño IMG_SIZE x IMG_SIZE.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdirname: directorio completo del que leer los datos\n",
    "\t\tmap_characters: variable de mapeo entre labels y personajes\n",
    "\t\tverbose: si es True, muestra información de las imágenes cargadas\n",
    "\n",
    "\tReturns:\n",
    "\t\tX, y: X es un array con todas las imágenes cargadas con tamaño\n",
    "\tIMG SIZE x IMG SIZE\n",
    "\t\t\t\ty es un array con las labels de correspondientes a cada imagen\n",
    "\t\"\"\"\n",
    "\tX_train = []\n",
    "\ty_train = []\n",
    "\tfor label, character in map_characters.items():        \n",
    "\t\tfiles = os.listdir(os.path.join(dirname, character))\n",
    "\t\timages = [file for file in files if file.endswith(\"jpg\")]\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(\"Leyendo {} imágenes encontradas de {}\".format(len(images), character))\n",
    "\t\tfor image_name in images:\n",
    "\t\t\timage = cv2.imread(os.path.join(dirname, character, image_name))\n",
    "\t\t\tX_train.append(cv2.resize(image,(IMG_SIZE, IMG_SIZE)))\n",
    "\t\t\ty_train.append(label)\n",
    "\treturn np.array(X_train), np.array(y_train)\n",
    "\n",
    "def load_test_set(dirname, map_characters, verbose=True):\n",
    "   \"\"\"Esta función funciona de manera equivalente a la función load_train_set\n",
    "   pero cargando los datos de test.\"\"\"\n",
    "   X_test = []\n",
    "   y_test = []\n",
    "   reverse_dict = {v: k for k, v in map_characters.items()}\n",
    "   for filename in glob.glob(dirname + '/*.*'):\n",
    "       char_name = \"_\".join(filename.split('/')[-1].split('_')[:-1])\n",
    "       if char_name in reverse_dict:\n",
    "           image = cv2.imread(filename)\n",
    "           image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "           X_test.append(image)\n",
    "           y_test.append(reverse_dict[char_name])\n",
    "   if verbose:\n",
    "       print(\"Leídas {} imágenes de test\".format(len(X_test)))\n",
    "   return np.array(X_test), np.array(y_test)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División del dataset en train y test\n",
    "Uso esta función para dividir el dataset en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_dataset(source_dir, dest_dir, split_ratio=0.3):\n",
    "\t\"\"\"\n",
    "\tEsta función divide el dataset en dos partes, una para training y otra para test, y lo pone en directorios distintos.\n",
    "\t\"\"\"\n",
    "\tif not os.path.exists(dest_dir):\n",
    "\t\tos.makedirs(dest_dir)\n",
    "\t\n",
    "\tfor character in os.listdir(source_dir):\n",
    "\t\tcharacter_path = os.path.join(source_dir, character)\n",
    "\t\tif os.path.isdir(character_path):\n",
    "\t\t\timages = [file for file in os.listdir(character_path) if file.endswith(\"jpg\")]\n",
    "\t\t\ttrain_images, test_images = train_test_split(images, test_size=split_ratio, random_state=42)\n",
    "\t\t\t\n",
    "\t\t\tcharacter_dest_path = os.path.join(dest_dir, character)\n",
    "\t\t\tif not os.path.exists(character_dest_path):\n",
    "\t\t\t\tos.makedirs(character_dest_path)\n",
    "\t\t\t\n",
    "\t\t\tfor image in test_images:\n",
    "\t\t\t\tshutil.move(os.path.join(character_path, image), os.path.join(character_dest_path, image))\n",
    "\n",
    "source_directory = \".\\\\Chessman-image-dataset\\\\Chess\"\n",
    "destination_directory = \".\\\\Chessman-image-dataset\\\\Chess_test\"\n",
    "split_dataset(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aumento de datos\n",
    "En esta celda utilizamos `ImageDataGenerator` de Keras para realizar aumentos de datos, como rotaciones, desplazamientos, zoom, etc., para mejorar la generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "Cargamos los datos de entrenamiento y prueba desde los directorios especificados y normalizamos las imágenes dividiendo los valores de los píxeles por 255.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo 49 imágenes encontradas de Bishop\n",
      "Leyendo 42 imágenes encontradas de King\n",
      "Leyendo 65 imágenes encontradas de Knight\n",
      "Leyendo 60 imágenes encontradas de Pawn\n",
      "Leyendo 46 imágenes encontradas de Queen\n",
      "Leyendo 60 imágenes encontradas de Rook\n",
      "Leídas 0 imágenes de test\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos. Si no estás trabajando en colab, cambia los paths por\n",
    "# los de los ficheros donde hayas descargado los datos.\n",
    "DATASET_TRAIN_PATH_COLAB = \".\\\\Chessman-image-dataset\\\\Chess\"\n",
    "DATASET_TEST_PATH_COLAB = \"Chessman-image-dataset\\\\Chess_test\"\n",
    "X, y = load_train_set(DATASET_TRAIN_PATH_COLAB, MAP_CHARACTERS)\n",
    "X_t, y_t = load_test_set(DATASET_TEST_PATH_COLAB, MAP_CHARACTERS)\n",
    "X = X / 255.0\n",
    "X_t = X_t / 255.0\n",
    "# Vamos a barajar aleatoriamente los datos. Esto es importante ya que si no\n",
    "# lo hacemos y, por ejemplo, cogemos el 20% de los datos finales como validation\n",
    "# set, estaremos utilizando solo un pequeño número de personajes, ya que\n",
    "# las imágenes se leen secuencialmente personaje a personaje.\n",
    "perm = np.random.permutation(len(X))\n",
    "X, y = X[perm], y[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de datos en entrenamiento y validación\n",
    "Separamos los datos en conjuntos de entrenamiento y validación utilizando `train_test_split` de `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (257, 150, 150, 3)\n",
      "Validation data shape: (65, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos los datos en training y validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de ejemplos\n",
    "Declaramos una función para visualizar las imágenes y mostramos un ejemplo de imagen normalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de elementos en X:  322\n"
     ]
    },
    {
     "data": {


     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [


     ]
    }
   ],
   "source": [
    " #Declaramos una función para visualizar las imágenes\n",
    "def visualize_example(x):\n",
    "\tplt.figure()\n",
    "\tplt.imshow(x)\n",
    "\tplt.colorbar()\n",
    "\tplt.grid(False)\n",
    "\tplt.show()\n",
    "print(\"Número de elementos en X: \",len(X))\n",
    "# for i in range(len(X)):\n",
    "# \tvisualize_example(X[i])\n",
    "# \tprint(MAP_CHARACTERS[y[i]])\n",
    " \n",
    "visualize_example(X[70]) # Visualiza la imagen normalizada con valores de 0 a 1\n",
    "print(MAP_CHARACTERS[y[70]]) # Acceso al diccionario\n",
    "print(X[70].shape[0:3]) # Dimensiones de la imagen tras resize con los 3 canales RGB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}