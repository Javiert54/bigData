{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimimos el archivo\n",
    "# !tar -xzf \"archive.zip\" -C \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una relación entre los nombres de las imágenes y las clases\n",
    "MAP_CHARACTERS = { 0: 'Bishop', 1: 'King', 2: 'Knight', 3: 'Pawn', 4: 'Queen', 5: 'Rook' }\n",
    "# Vamos a standarizar todas las imágenes a tamaño 64x64\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_set(dirname, map_characters, verbose=True):\n",
    "\t\"\"\"Esta función carga los datos de training en imágenes.\n",
    "\n",
    "\tComo las imágenes tienen tamaños distintas, utilizamos la librería opencv\n",
    "\tpara hacer un resize y adaptarlas todas a tamaño IMG_SIZE x IMG_SIZE.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdirname: directorio completo del que leer los datos\n",
    "\t\tmap_characters: variable de mapeo entre labels y personajes\n",
    "\t\tverbose: si es True, muestra información de las imágenes cargadas\n",
    "\n",
    "\tReturns:\n",
    "\t\tX, y: X es un array con todas las imágenes cargadas con tamaño\n",
    "\tIMG SIZE x IMG SIZE\n",
    "\t\t\t\ty es un array con las labels de correspondientes a cada imagen\n",
    "\t\"\"\"\n",
    "\tX_train = []\n",
    "\ty_train = []\n",
    "\tfor label, character in map_characters.items():        \n",
    "\t\tfiles = os.listdir(os.path.join(dirname, character))\n",
    "\t\timages = [file for file in files if file.endswith(\"jpg\")]\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(\"Leyendo {} imágenes encontradas de {}\".format(len(images), character))\n",
    "\t\tfor image_name in images:\n",
    "\t\t\timage = cv2.imread(os.path.join(dirname, character, image_name))\n",
    "\t\t\tX_train.append(cv2.resize(image,(IMG_SIZE, IMG_SIZE)))\n",
    "\t\t\ty_train.append(label)\n",
    "\treturn np.array(X_train), np.array(y_train)\n",
    "\n",
    "def load_test_set(dirname, map_characters, verbose=True):\n",
    "   \"\"\"Esta función funciona de manera equivalente a la función load_train_set\n",
    "   pero cargando los datos de test.\"\"\"\n",
    "   X_test = []\n",
    "   y_test = []\n",
    "   reverse_dict = {v: k for k, v in map_characters.items()}\n",
    "   for filename in glob.glob(dirname + '/*.*'):\n",
    "       char_name = \"_\".join(filename.split('/')[-1].split('_')[:-1])\n",
    "       if char_name in reverse_dict:\n",
    "           image = cv2.imread(filename)\n",
    "           image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "           X_test.append(image)\n",
    "           y_test.append(reverse_dict[char_name])\n",
    "   if verbose:\n",
    "       print(\"Leídas {} imágenes de test\".format(len(X_test)))\n",
    "   return np.array(X_test), np.array(y_test)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_dataset(source_dir, dest_dir, split_ratio=0.3):\n",
    "\t\"\"\"\n",
    "\tEsta función divide el dataset en dos partes, una para training y otra para test, y lo pone en directorios distintos.\n",
    "\t\"\"\"\n",
    "\tif not os.path.exists(dest_dir):\n",
    "\t\tos.makedirs(dest_dir)\n",
    "\t\n",
    "\tfor character in os.listdir(source_dir):\n",
    "\t\tcharacter_path = os.path.join(source_dir, character)\n",
    "\t\tif os.path.isdir(character_path):\n",
    "\t\t\timages = [file for file in os.listdir(character_path) if file.endswith(\"jpg\")]\n",
    "\t\t\ttrain_images, test_images = train_test_split(images, test_size=split_ratio, random_state=42)\n",
    "\t\t\t\n",
    "\t\t\tcharacter_dest_path = os.path.join(dest_dir, character)\n",
    "\t\t\tif not os.path.exists(character_dest_path):\n",
    "\t\t\t\tos.makedirs(character_dest_path)\n",
    "\t\t\t\n",
    "\t\t\tfor image in test_images:\n",
    "\t\t\t\tshutil.move(os.path.join(character_path, image), os.path.join(character_dest_path, image))\n",
    "\n",
    "source_directory = \".\\\\Chessman-image-dataset\\\\Chess\"\n",
    "destination_directory = \".\\\\Chessman-image-dataset\\\\Chess_test\"\n",
    "split_dataset(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo 23 imágenes encontradas de Bishop\n",
      "Leyendo 20 imágenes encontradas de King\n",
      "Leyendo 31 imágenes encontradas de Knight\n",
      "Leyendo 29 imágenes encontradas de Pawn\n",
      "Leyendo 22 imágenes encontradas de Queen\n",
      "Leyendo 29 imágenes encontradas de Rook\n",
      "Leídas 0 imágenes de test\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos. Si no estás trabajando en colab, cambia los paths por\n",
    "# los de los ficheros donde hayas descargado los datos.\n",
    "DATASET_TRAIN_PATH_COLAB = \".\\\\Chessman-image-dataset\\\\Chess\"\n",
    "DATASET_TEST_PATH_COLAB = \"Chessman-image-dataset\\\\Chess_test\"\n",
    "X, y = load_train_set(DATASET_TRAIN_PATH_COLAB, MAP_CHARACTERS)\n",
    "X_t, y_t = load_test_set(DATASET_TEST_PATH_COLAB, MAP_CHARACTERS)\n",
    "# Vamos a barajar aleatoriamente los datos. Esto es importante ya que si no\n",
    "# lo hacemos y, por ejemplo, cogemos el 20% de los datos finales como validation\n",
    "# set, estaremos utilizando solo un pequeño número de personajes, ya que\n",
    "# las imágenes se leen secuencialmente personaje a personaje.\n",
    "perm = np.random.permutation(len(X))\n",
    "X, y = X[perm], y[perm]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
