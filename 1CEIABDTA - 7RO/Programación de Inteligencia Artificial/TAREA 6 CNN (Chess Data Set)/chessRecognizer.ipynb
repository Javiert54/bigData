{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí sería donde descomprimo el dataset, pero como estoy usando jupyter. Puedo hacerlo yo manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def eliminar_carpetas(carpeta):\n",
    "    if os.path.exists(carpeta):\n",
    "        shutil.rmtree(carpeta)\n",
    "        print(f\"Carpeta '{carpeta}' eliminada.\")\n",
    "    else:\n",
    "        print(f\"La carpeta '{carpeta}' no existe.\")\n",
    "\n",
    "def extraer_zip(archivo_zip, destino):\n",
    "    with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(destino)\n",
    "        print(f\"Archivo '{archivo_zip}' extraído en '{destino}'.\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "carpeta_a_eliminar = 'ruta/a/tu/carpeta'\n",
    "archivo_zip = 'ruta/a/tu/archivo.zip'\n",
    "destino_extraccion = 'ruta/a/tu/destino'\n",
    "\n",
    "eliminar_carpetas(\"Chessman-image-dataset\")\n",
    "extraer_zip(\"archive.zip\", \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una relación entre los nombres de las imágenes y las clases\n",
    "MAP_CHARACTERS = { 0: 'Bishop', 1: 'King', 2: 'Knight', 3: 'Pawn', 4: 'Queen', 5: 'Rook' }\n",
    "# Vamos a standarizar todas las imágenes a tamaño 64x64\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos dos funciones para cargar los datos. Una dedicada a la fracción train y la otra para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_set(dirname, map_characters, verbose=True):\n",
    "\t\"\"\"Esta función carga los datos de training en imágenes.\n",
    "\n",
    "\tComo las imágenes tienen tamaños distintas, utilizamos la librería opencv\n",
    "\tpara hacer un resize y adaptarlas todas a tamaño IMG_SIZE x IMG_SIZE.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdirname: directorio completo del que leer los datos\n",
    "\t\tmap_characters: variable de mapeo entre labels y personajes\n",
    "\t\tverbose: si es True, muestra información de las imágenes cargadas\n",
    "\n",
    "\tReturns:\n",
    "\t\tX, y: X es un array con todas las imágenes cargadas con tamaño\n",
    "\tIMG SIZE x IMG SIZE\n",
    "\t\t\t\ty es un array con las labels de correspondientes a cada imagen\n",
    "\t\"\"\"\n",
    "\tX_train = []\n",
    "\ty_train = []\n",
    "\tfor label, character in map_characters.items():        \n",
    "\t\tfiles = os.listdir(os.path.join(dirname, character))\n",
    "\t\timages = [file for file in files if file.endswith(\"jpg\")]\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(\"Leyendo {} imágenes encontradas de {}\".format(len(images), character))\n",
    "\t\tfor image_name in images:\n",
    "\t\t\timage = cv2.imread(os.path.join(dirname, character, image_name))\n",
    "\t\t\tX_train.append(cv2.resize(image,(IMG_SIZE, IMG_SIZE)))\n",
    "\t\t\ty_train.append(label)\n",
    "\treturn np.array(X_train), np.array(y_train)\n",
    "\n",
    "def load_test_set(dirname, map_characters, verbose=True):\n",
    "   \"\"\"Esta función funciona de manera equivalente a la función load_train_set\n",
    "   pero cargando los datos de test.\"\"\"\n",
    "   X_test = []\n",
    "   y_test = []\n",
    "   reverse_dict = {v: k for k, v in map_characters.items()}\n",
    "   for filename in glob.glob(dirname + '/*.*'):\n",
    "       char_name = \"_\".join(filename.split('/')[-1].split('_')[:-1])\n",
    "       if char_name in reverse_dict:\n",
    "           image = cv2.imread(filename)\n",
    "           image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "           X_test.append(image)\n",
    "           y_test.append(reverse_dict[char_name])\n",
    "   if verbose:\n",
    "       print(\"Leídas {} imágenes de test\".format(len(X_test)))\n",
    "   return np.array(X_test), np.array(y_test)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso esta función para dividir el dataset en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_dataset(source_dir, dest_dir, split_ratio=0.3):\n",
    "\t\"\"\"\n",
    "\tEsta función divide el dataset en dos partes, una para training y otra para test, y lo pone en directorios distintos.\n",
    "\t\"\"\"\n",
    "\tif not os.path.exists(dest_dir):\n",
    "\t\tos.makedirs(dest_dir)\n",
    "\t\n",
    "\tfor character in os.listdir(source_dir):\n",
    "\t\tcharacter_path = os.path.join(source_dir, character)\n",
    "\t\tif os.path.isdir(character_path):\n",
    "\t\t\timages = [file for file in os.listdir(character_path) if file.endswith(\"jpg\")]\n",
    "\t\t\ttrain_images, test_images = train_test_split(images, test_size=split_ratio, random_state=42)\n",
    "\t\t\t\n",
    "\t\t\tcharacter_dest_path = os.path.join(dest_dir, character)\n",
    "\t\t\tif not os.path.exists(character_dest_path):\n",
    "\t\t\t\tos.makedirs(character_dest_path)\n",
    "\t\t\t\n",
    "\t\t\tfor image in test_images:\n",
    "\t\t\t\tshutil.move(os.path.join(character_path, image), os.path.join(character_dest_path, image))\n",
    "\n",
    "source_directory = \".\\\\Chessman-image-dataset\\\\Chess\"\n",
    "destination_directory = \".\\\\Chessman-image-dataset\\\\Chess_test\"\n",
    "split_dataset(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo 2 imágenes encontradas de Bishop\n",
      "Leyendo 2 imágenes encontradas de King\n",
      "Leyendo 4 imágenes encontradas de Knight\n",
      "Leyendo 4 imágenes encontradas de Pawn\n",
      "Leyendo 2 imágenes encontradas de Queen\n",
      "Leyendo 4 imágenes encontradas de Rook\n",
      "Leídas 0 imágenes de test\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos. Si no estás trabajando en colab, cambia los paths por\n",
    "# los de los ficheros donde hayas descargado los datos.\n",
    "DATASET_TRAIN_PATH_COLAB = \".\\\\Chessman-image-dataset\\\\Chess\"\n",
    "DATASET_TEST_PATH_COLAB = \"Chessman-image-dataset\\\\Chess_test\"\n",
    "X, y = load_train_set(DATASET_TRAIN_PATH_COLAB, MAP_CHARACTERS)\n",
    "X_t, y_t = load_test_set(DATASET_TEST_PATH_COLAB, MAP_CHARACTERS)\n",
    "X = X / 255.0\n",
    "X_t = X_t / 255.0\n",
    "# Vamos a barajar aleatoriamente los datos. Esto es importante ya que si no\n",
    "# lo hacemos y, por ejemplo, cogemos el 20% de los datos finales como validation\n",
    "# set, estaremos utilizando solo un pequeño número de personajes, ya que\n",
    "# las imágenes se leen secuencialmente personaje a personaje.\n",
    "perm = np.random.permutation(len(X))\n",
    "X, y = X[perm], y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (14, 64, 64, 3)\n",
      "Validation data shape: (4, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos los datos en training y validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 70 is out of bounds for axis 0 with size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \tplt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \tplt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m----> 8\u001b[0m visualize_example(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m# Visualiza la imagen normalizada con valores de 0 a 1\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(MAP_CHARACTERS[y[\u001b[38;5;241m70\u001b[39m]]) \u001b[38;5;66;03m# Acceso al diccionario\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(X[\u001b[38;5;241m70\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]) \u001b[38;5;66;03m# Dimensiones de la imagen tras resize con los 3 canales RGB\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 70 is out of bounds for axis 0 with size 18"
     ]
    }
   ],
   "source": [
    " #Declaramos una función para visualizar las imágenes\n",
    "def visualize_example(x):\n",
    "\tplt.figure()\n",
    "\tplt.imshow(x)\n",
    "\tplt.colorbar()\n",
    "\tplt.grid(False)\n",
    "\tplt.show()\n",
    "visualize_example(X[70]) # Visualiza la imagen normalizada con valores de 0 a 1\n",
    "print(MAP_CHARACTERS[y[70]]) # Acceso al diccionario\n",
    "print(X[70].shape[0:3]) # Dimensiones de la imagen tras resize con los 3 canales RGB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
