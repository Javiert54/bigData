{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Javier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "def export_model(model_name: str):\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    model.save_pretrained(model_name)\n",
    "    processor.save_pretrained(model_name)\n",
    "    return model, processor\n",
    "if not os.path.exists(\"openai/whisper-base\"):\n",
    "    model, procesor = export_model(\"openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "def load_model(model_name: str):\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    return model, processor\n",
    "\n",
    "# Uso\n",
    "model_name = \"./openai/whisper-base\"\n",
    "model, processor = load_model(\"./openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completa:\n",
      "Thank you everyone and cut!  I don't care if Monday's blue Tuesday is grey and Wednesday too Thursday I don't care about you it's Friday I'm in love I'm there you can fall apart Tuesday Wednesday break my heart all Thursday doesn't even stop it's Friday I'm in love  Saturday  One day you can hold your hand Choose day when say stay in bed of Thursday Watch the walls instead it's Friday, I live love Saturday, wait Sunday always comes to  I'm  Friday I'm in love I don't care if my face blue Choose this prayer when stay tuned First day I don't care but choose this Friday I'm in love  Oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh,  you\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def transcribe_long_audio(model, processor, audio_path: str):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    duration_ms = len(audio)\n",
    "    segment_duration_ms = 30 * 1000  # 30 seconds in milliseconds\n",
    "\n",
    "    segments = []\n",
    "    for start_ms in range(0, duration_ms, segment_duration_ms):\n",
    "        end_ms = min(start_ms + segment_duration_ms, duration_ms)\n",
    "        segment = audio[start_ms:end_ms]\n",
    "        segments.append(segment)\n",
    "\n",
    "    full_transcription = \"\"\n",
    "    for i, segment in enumerate(segments):\n",
    "        segment_path = f\"segment_{i}.wav\"\n",
    "        segment.export(segment_path, format=\"wav\")\n",
    "\n",
    "        audio_data, _ = librosa.load(segment_path, sr=16000)\n",
    "        input_features = processor(audio_data, return_tensors=\"pt\", sampling_rate=16000).input_features\n",
    "        input_features = input_features.to(device)\n",
    "        generated_ids = model.generate(input_features)\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        full_transcription += transcription + \" \"\n",
    "\n",
    "        os.remove(segment_path)\n",
    "\n",
    "    return full_transcription.strip()\n",
    "\n",
    "audio_path = \"ytmp3free.cc_the-cure-friday-im-in-love-youtubemp3free.org.mp3\"\n",
    "if __name__ == \"__main__\":\n",
    "    transcription = transcribe_long_audio(model, processor, audio_path)\n",
    "    print(\"Transcripción completa:\")\n",
    "    print(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
