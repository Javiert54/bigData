{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_name = \"/openai/whisper-base\"\n",
    "audio_path = \"ytmp3free.cc_the-cure-friday-im-in-love-youtubemp3free.org.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Javier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def export_model(model_name: str):\n",
    "    \"\"\"\n",
    "        Función que exporta el modelo y el procesador de Whisper a un directorio\n",
    "        Args:\n",
    "            model_name: str, nombre del modelo a exportar\n",
    "    \"\"\"\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    model.save_pretrained(model_name)\n",
    "    processor.save_pretrained(model_name)\n",
    "    return model, processor\n",
    "\n",
    "if not os.path.exists(\"openai/whisper-base\"): \n",
    "    model, processor = export_model(\"openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name: str):\n",
    "    \"\"\"\n",
    "        Función que carga el modelo y el procesador de Whisper desde un directorio\n",
    "        Args:\n",
    "            model_name: str, nombre del directorio donde se encuentra el modelo y el procesador\n",
    "    \"\"\"\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "model, processor = load_model(\"./openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(audio_path: str, segment_duration_ms: int = 30000):\n",
    "    \"\"\"\n",
    "        Función generador que segmenta un audio en segmentos de duración segment_duration_ms y los exporta a archivos .wav\n",
    "        Args:\n",
    "            audio_path: str, ruta al audio a segmentar\n",
    "            segment_duration_ms: int, duración de los segmentos en milisegundos\n",
    "    \"\"\"\n",
    "    \n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    duration_ms = len(audio)\n",
    "\n",
    "    for start_ms in range(0, duration_ms, segment_duration_ms):\n",
    "        end_ms = min(start_ms + segment_duration_ms, duration_ms)\n",
    "        segment = audio[start_ms:end_ms]\n",
    "        segment_path = f\"segment_{start_ms // segment_duration_ms}.wav\"\n",
    "        segment.export(segment_path, format=\"wav\")\n",
    "        yield segment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completa:\n",
      "Thank you everyone and cut!\n",
      " I don't care if Monday's blue Tuesday is grey and Wednesday too Thursday I don't care about you it's Friday I'm in love I'm there you can fall apart Tuesday Wednesday break my heart all Thursday doesn't even stop it's Friday I'm in love\n",
      " Saturday\n",
      " One day you can hold your hand Choose day when say stay in bed of Thursday Watch the walls instead it's Friday, I live love Saturday, wait Sunday always comes to\n",
      " I'm\n",
      " Friday I'm in love I don't care if my face blue Choose this prayer when stay tuned First day I don't care but choose this Friday I'm in love\n",
      " Oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh,\n",
      " you\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def transcribe_long_audio(model:WhisperForConditionalGeneration, processor:WhisperProcessor, audio_path: str):\n",
    "    \"\"\"\n",
    "        Función que transcribe un audio largo dividiéndolo en segmentos de 30 segundos\n",
    "        Args:\n",
    "            model: WhisperForConditionalGeneration, modelo de Whisper\n",
    "            processor: WhisperProcessor, procesador de Whisper\n",
    "            audio_path: str, ruta al audio\n",
    "    \"\"\"\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    full_transcription = \"\"\n",
    "    for segment_path in segment_audio(audio_path):\n",
    "\n",
    "        audio_data, _ = librosa.load(segment_path, sr=16000)\n",
    "        input_features = processor(audio_data, return_tensors=\"pt\", sampling_rate=16000).input_features\n",
    "        input_features = input_features.to(device)\n",
    "        generated_ids = model.generate(input_features)\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        full_transcription += transcription + \"\\n\"\n",
    "\n",
    "        os.remove(segment_path)\n",
    "\n",
    "    return full_transcription.strip()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transcription = transcribe_long_audio(model, processor, audio_path)\n",
    "    print(\"Transcripción completa:\")\n",
    "    print(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
