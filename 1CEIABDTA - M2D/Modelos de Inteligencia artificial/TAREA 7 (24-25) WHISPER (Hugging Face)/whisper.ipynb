{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "#  INSTALAR WHISPER CON EL SIGUIENTE COMANDO:\n",
    "# pip install git+https://github.com/openai/whisper.git \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "    # Seleccionamos el modelo que queremos utilizar\n",
    "model_name= [\"openai/whisper-tiny\", \"openai/whisper-base\", \n",
    "             \"openai/whisper-small\", \"openai/whisper-medium\", \n",
    "             \"openai/whisper-large\", \"openai/whisper-large-v2\"][3] \n",
    "\n",
    "    # Especificamos el archivo de audio que queremos utilizar\n",
    "audio_path = \"ytmp3free.cc_the-cure-friday-im-in-love-youtubemp3free.org.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model_name: str):\n",
    "    \"\"\"\n",
    "        Función que exporta el modelo y el procesador de Whisper a un directorio\n",
    "        Args:\n",
    "            model_name: str, nombre del modelo a exportar\n",
    "    \"\"\"\n",
    "    # Cargar el procesador desde el modelo preentrenado especificado\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    # Cargar el modelo desde el modelo preentrenado especificado\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    # Guardar el modelo en el directorio especificado por model_name\n",
    "    model.save_pretrained(model_name)\n",
    "    # Guardar el procesador en el mismo directorio\n",
    "    processor.save_pretrained(model_name)\n",
    "    return model, processor\n",
    "\n",
    "# Verificar si el directorio del modelo no existe\n",
    "if not os.path.exists(model_name): \n",
    "    # Exportar el modelo y el procesador si el directorio no existe\n",
    "    model, processor = export_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name: str):\n",
    "    \"\"\"\n",
    "        Función que carga el modelo y el procesador de Whisper desde un directorio\n",
    "        Args:\n",
    "            model_name: str, nombre del directorio donde se encuentra el modelo y el procesador\n",
    "    \"\"\"\n",
    "    # Cargar el procesador desde el directorio especificado\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    # Cargar el modelo desde el directorio especificado\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    return model, processor\n",
    "\n",
    "# Cargar el modelo y el procesador utilizando el nombre del modelo especificado\n",
    "model, processor = load_model(\"./\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(audio_path: str, segment_duration_ms: int = 30000):\n",
    "    \"\"\"\n",
    "        Función generador que segmenta un audio en segmentos de duración segment_duration_ms y los exporta a archivos .wav\n",
    "        Args:\n",
    "            audio_path: str, ruta al audio a segmentar\n",
    "            segment_duration_ms: int, duración de los segmentos en milisegundos\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cargar el archivo de audio\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    # Obtener la duración del audio en milisegundos\n",
    "    duration_ms = len(audio)\n",
    "\n",
    "    # Iterar sobre el audio en pasos de segment_duration_ms\n",
    "    for start_ms in range(0, duration_ms, segment_duration_ms):\n",
    "        # Calcular el final del segmento\n",
    "        end_ms = min(start_ms + segment_duration_ms, duration_ms)\n",
    "        # Extraer el segmento del audio\n",
    "        segment = audio[start_ms:end_ms]\n",
    "        # Definir el nombre del archivo del segmento\n",
    "        segment_path = f\"segment_{start_ms // segment_duration_ms}.wav\"\n",
    "        # Exportar el segmento a un archivo .wav\n",
    "        segment.export(segment_path, format=\"wav\")\n",
    "        # Devolver la ruta del archivo del segmento\n",
    "        yield segment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_long_audio(model: WhisperForConditionalGeneration, processor: WhisperProcessor, audio_path: str):\n",
    "    \"\"\"\n",
    "        Función que transcribe un audio largo dividiéndolo en segmentos de 30 segundos\n",
    "        Args:\n",
    "            model: WhisperForConditionalGeneration, modelo de Whisper\n",
    "            processor: WhisperProcessor, procesador de Whisper\n",
    "            audio_path: str, ruta al audio\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determinar si se utilizará GPU o CPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    full_transcription = \"\"  # Variable para almacenar la transcripción completa\n",
    "\n",
    "    # Segmentar el audio y transcribir cada segmento\n",
    "    for segment_path in segment_audio(audio_path):\n",
    "        # Cargar el segmento de audio\n",
    "        audio_data, _ = librosa.load(segment_path, sr=16000)\n",
    "        # Procesar el audio para obtener las características de entrada\n",
    "        input_features = processor(audio_data, return_tensors=\"pt\", sampling_rate=16000).input_features\n",
    "        input_features = input_features.to(device)\n",
    "        # Generar la transcripción del segmento\n",
    "        generated_ids = model.generate(input_features)\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        # Agregar la transcripción del segmento a la transcripción completa\n",
    "        full_transcription += transcription + \"\\n\"\n",
    "        # Eliminar el archivo de segmento de audio\n",
    "        os.remove(segment_path)\n",
    "\n",
    "    return full_transcription.strip()  # Devolver la transcripción completa sin espacios en blanco al inicio y al final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completa:\n",
      "Stand by everyone and...CUT!\n",
      " I don't care if Monday's blue Tuesday's gray and Wednesday too Thursday, I don't care about you It's Friday, I'm in love Monday you can fall apart Tuesday, Wednesday break my heart Oh Thursday doesn't even start It's Friday, I'm in love\n",
      " Saturday way Sunday always comes to me Friday never has it end I don't care if Monday's black Tuesday, Wednesday, heart attack Thursday never looking back It's Friday, I'm in love\n",
      " Tuesday Wednesday\n",
      " See your shoes\n",
      " It's Friday, I'm in love! I don't care if Monday's blue Tuesday's gray and Wednesday too Thursday, I don't care about you It's Friday, I'm in love Monday you can fall apart Tuesday, Wednesday break my heart Thursday doesn't even start It's Friday, I'm in love\n",
      " Oh\n",
      " you\n"
     ]
    }
   ],
   "source": [
    "# Ejecutamos el código\n",
    "if __name__ == \"__main__\":\n",
    "    transcription = transcribe_long_audio(model, processor, audio_path)\n",
    "    print(\"Transcripción completa:\")\n",
    "    print(transcription)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
